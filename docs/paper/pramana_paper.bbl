\begin{thebibliography}{32}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Burton(2020)]{burton2020diagrams}
Jim Burton.
\newblock Diagrams for navya-nyāya.
\newblock \emph{Journal of Indian Philosophy}, 48\penalty0 (5):\penalty0
  747--801, 2020.
\newblock \doi{10.1007/s10781-020-09419-0}.

\bibitem[Clark et~al.(2020)Clark, Tafjord, and Richardson]{ruletaker-2020}
Peter Clark, Oyvind Tafjord, and Kyle Richardson.
\newblock Transformers as soft reasoners over language.
\newblock In \emph{Proceedings of the Twenty-Ninth International Joint
  Conference on Artificial Intelligence}, pages 3882--3890, 2020.
\newblock \doi{10.24963/ijcai.2020/538}.

\bibitem[de~Moura and Bj{\o}rner(2008)]{z3-2008}
Leonardo de~Moura and Nikolaj Bj{\o}rner.
\newblock Z3: An efficient smt solver.
\newblock In \emph{Tools and Algorithms for the Construction and Analysis of
  Systems}, pages 337--340. Springer, 2008.
\newblock \doi{10.1007/978-3-540-78800-3_24}.

\bibitem[DeepSeek-AI(2024)]{grpo-2024}
DeepSeek-AI.
\newblock Group relative policy optimization.
\newblock \emph{arXiv preprint arXiv:2505.22257}, 2024.
\newblock Used in DeepSeek-R1 training.

\bibitem[DeepSeek-AI(2025)]{deepseek-r1-2025}
DeepSeek-AI.
\newblock Deepseek-r1: Incentivizing reasoning capability in llms via
  reinforcement learning.
\newblock \emph{arXiv preprint arXiv:2501.12948}, 2025.
\newblock URL \url{https://arxiv.org/abs/2501.12948}.

\bibitem[Deng and Mineiro(2024)]{flow-dpo-2024}
Yihe Deng and Paul Mineiro.
\newblock Flow-dpo: Improving llm mathematical reasoning through online
  multi-agent learning.
\newblock \emph{arXiv preprint arXiv:2412.16145}, 2024.
\newblock URL \url{https://arxiv.org/abs/2412.16145}.

\bibitem[Dettmers et~al.(2023)Dettmers, Pagnoni, Holtzman, and
  Zettlemoyer]{qlora-2023}
Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, and Luke Zettlemoyer.
\newblock Qlora: Efficient finetuning of quantized llms.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~36, 2023.
\newblock URL \url{https://arxiv.org/abs/2305.14314}.

\bibitem[Dhuliawala et~al.(2024)Dhuliawala, Komeili, Xu, Raileanu, Li,
  Celikyilmaz, and Weston]{cove-2024}
Shehzaad Dhuliawala, Mojtaba Komeili, Jing Xu, Roberta Raileanu, Xian Li, Asli
  Celikyilmaz, and Jason Weston.
\newblock Chain-of-verification reduces hallucination in large language models.
\newblock In \emph{Findings of the Association for Computational Linguistics:
  ACL 2024}, pages 2693--2708, 2024.
\newblock \doi{10.18653/v1/2024.findings-acl.212}.

\bibitem[Fedin et~al.(2025)]{proofnet-plus-2025}
Oleg Fedin et~al.
\newblock Proofnet++: A neuro-symbolic system for formal proof verification
  with self-correction.
\newblock \emph{arXiv preprint arXiv:2505.24230}, 2025.
\newblock URL \url{https://arxiv.org/abs/2505.24230}.

\bibitem[Ganeri(2000)]{indian-logic-ai}
Jonardon Ganeri.
\newblock Indian logic and ai system design.
\newblock In \emph{Proceedings of the International Conference on Knowledge
  Engineering}, 2000.
\newblock Available at academia.edu.

\bibitem[Ganeri(2001)]{ganeri2001philosophy}
Jonardon Ganeri.
\newblock Philosophy in classical india: The proper work of reason.
\newblock \emph{Philosophy East and West}, 2001.

\bibitem[Ganeri(2012)]{ancient-indian-logic-case-based}
Jonardon Ganeri.
\newblock Ancient indian logic as a theory of case-based reasoning.
\newblock \emph{ResearchGate}, 2012.
\newblock URL \url{https://www.researchgate.net/publication/251381865}.

\bibitem[Garcez et~al.(2019)Garcez, Gori, Lamb, Serafini, Spranger, and
  Tran]{garcez2019neural}
Artur~d'Avila Garcez, Marco Gori, Luis~C. Lamb, Luciano Serafini, Michael
  Spranger, and Son~N. Tran.
\newblock Neural-symbolic computing: An effective methodology for principled
  integration of machine learning and reasoning.
\newblock \emph{Journal of Applied Logics}, 6\penalty0 (4):\penalty0 611--632,
  2019.

\bibitem[Gaṅgeśa(1325)]{tattvacintamani}
Upādhyāya Gaṅgeśa.
\newblock \emph{Tattvacintāmaṇi}.
\newblock Various editions, 1325.
\newblock Foundational text of Navya-Nyaya logic.

\bibitem[Han and Han(2024)]{unsloth-2024}
Daniel Han and Michael Han.
\newblock Unsloth: Fast and memory-efficient fine-tuning of large language
  models, 2024.
\newblock URL \url{https://docs.unsloth.ai/}.
\newblock Open-source library for efficient LLM fine-tuning.

\bibitem[Hu et~al.(2021)Hu, Shen, Wallis, Allen-Zhu, Li, Wang, Wang, and
  Chen]{lora-2021}
Edward~J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean
  Wang, Lu~Wang, and Weizhu Chen.
\newblock Lora: Low-rank adaptation of large language models.
\newblock \emph{arXiv preprint arXiv:2106.09685}, 2021.
\newblock URL \url{https://arxiv.org/abs/2106.09685}.

\bibitem[Kulkarni(2018)]{kulkarni2018later}
Amba Kulkarni.
\newblock Later nyāya logic: Computational aspects.
\newblock In Jonardon Ganeri, editor, \emph{Handbook of Logical Thought in
  India}, pages 1--30. Springer, 2018.
\newblock \doi{10.1007/978-81-322-1812-8_12-1}.

\bibitem[Lightman et~al.(2023)Lightman, Cobbe, and Schulman]{lightman2023prm}
Hunter Lightman, Vineet Cobbe, and John Schulman.
\newblock Let's verify step by step.
\newblock \emph{arXiv preprint arXiv:2305.20050}, 2023.
\newblock URL \url{https://arxiv.org/abs/2305.20050}.

\bibitem[Matilal(1985)]{matilal1985logic}
Bimal~Krishna Matilal.
\newblock \emph{Logic, language, and reality: Indian philosophy and
  contemporary issues}.
\newblock Motilal Banarsidass, Delhi, 1985.

\bibitem[Mihir3009 et~al.(2024)]{logicbench-2024}
Mihir3009 et~al.
\newblock Logicbench: Towards systematic evaluation of logical reasoning
  ability of large language models.
\newblock In \emph{Proceedings of the 62nd Annual Meeting of the Association
  for Computational Linguistics}, 2024.
\newblock URL \url{https://aclanthology.org/2024.acl-long.739/}.

\bibitem[Research(2024{\natexlab{a}})]{apple-gsm-symbolic-2024}
Apple Machine~Learning Research.
\newblock Gsm-symbolic: Understanding the limitations of mathematical reasoning
  in large language models.
\newblock \emph{arXiv preprint arXiv:2410.05229}, October 2024{\natexlab{a}}.
\newblock URL \url{https://arxiv.org/abs/2410.05229}.

\bibitem[Research(2024{\natexlab{b}})]{illusion-thinking-2024}
Apple Machine~Learning Research.
\newblock The illusion of thinking: Understanding the strengths and limitations
  of reasoning models via the lens of problem complexity.
\newblock \emph{Apple Machine Learning Research}, October 2024{\natexlab{b}}.
\newblock URL
  \url{https://machinelearning.apple.com/research/illusion-of-thinking}.

\bibitem[Saparov et~al.(2023)]{prontoqa-2023}
Abulhair Saparov et~al.
\newblock Prontoqa: Proof and ontology-generated question-answering.
\newblock \emph{arXiv preprint arXiv:2306.14077}, 2023.
\newblock URL \url{https://arxiv.org/abs/2306.14077}.

\bibitem[Sarma(1994)]{sarma1994survey}
V.~V.~S. Sarma.
\newblock A survey of indian logic from the point of view of computer science.
\newblock \emph{Sadhana}, 19\penalty0 (6):\penalty0 971--983, 1994.

\bibitem[Various(2024{\natexlab{a}})]{proof-of-thought-2024}
Various.
\newblock Proof of thought: Neurosymbolic program synthesis allows robust and
  interpretable reasoning.
\newblock \emph{arXiv preprint arXiv:2409.17270}, 2024{\natexlab{a}}.
\newblock URL \url{https://arxiv.org/abs/2409.17270}.

\bibitem[Various(2024{\natexlab{b}})]{verge-2024}
Various.
\newblock Verge: Verification-guided reasoning for large language models.
\newblock \emph{arXiv preprint arXiv:2601.20055}, 2024{\natexlab{b}}.
\newblock URL \url{https://arxiv.org/abs/2601.20055}.

\bibitem[Various(2025{\natexlab{a}})]{cognitive-foundations-2025}
Various.
\newblock Cognitive foundations for reasoning and their manifestation in llms.
\newblock \emph{arXiv preprint arXiv:2511.16660}, 2025{\natexlab{a}}.
\newblock URL \url{https://arxiv.org/abs/2511.16660}.

\bibitem[Various(2025{\natexlab{b}})]{vericot-2025}
Various.
\newblock Vericot: Neuro-symbolic chain-of-thought validation via logical
  consistency checks.
\newblock \emph{arXiv preprint arXiv:2511.04662}, 2025{\natexlab{b}}.
\newblock URL \url{https://arxiv.org/abs/2511.04662}.

\bibitem[Wang et~al.(2023)Wang, Min, Deng, Shen, Wu, Zettlemoyer, and
  Sun]{wang2023understanding}
Boshi Wang, Sewon Min, Xiang Deng, Jiaming Shen, You Wu, Luke Zettlemoyer, and
  Huan Sun.
\newblock Towards understanding chain-of-thought prompting: An empirical study
  of what matters.
\newblock In \emph{Proceedings of the 61st Annual Meeting of the Association
  for Computational Linguistics}, pages 2717--2739, 2023.
\newblock \doi{10.18653/v1/2023.acl-long.153}.

\bibitem[Wei et~al.(2022)Wei, Wang, Schuurmans, Bosma, Ichter, Xia, Chi, Le,
  and Zhou]{wei2022chain}
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia,
  Ed~Chi, Quoc~V. Le, and Denny Zhou.
\newblock Chain-of-thought prompting elicits reasoning in large language
  models.
\newblock \emph{Advances in Neural Information Processing Systems},
  35:\penalty0 24824--24837, 2022.
\newblock URL
  \url{https://proceedings.neurips.cc/paper/2022/hash/9d5609613524ecf4f15af0f7b31abca4-Abstract.html}.

\bibitem[Zhang et~al.(2025{\natexlab{a}})]{halluclean-2025}
Yuxiang Zhang et~al.
\newblock Halluclean: A unified framework for detecting and correcting
  hallucinations in large language models.
\newblock \emph{arXiv preprint arXiv:2511.08916}, 2025{\natexlab{a}}.
\newblock URL \url{https://arxiv.org/abs/2511.08916}.

\bibitem[Zhang et~al.(2025{\natexlab{b}})]{reasonflux-prm-2025}
Yuxiang Zhang et~al.
\newblock Reasonflux-prm: Trajectory-aware prms for long chain-of-thought
  reasoning in llms.
\newblock \emph{arXiv preprint arXiv:2506.18896}, 2025{\natexlab{b}}.
\newblock URL \url{https://arxiv.org/abs/2506.18896}.

\end{thebibliography}
