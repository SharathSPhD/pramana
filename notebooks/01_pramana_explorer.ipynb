{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Pramana Explorer: Interactive Navya-Nyaya Reasoning Demo\n",
        "\n",
        "This notebook provides an interactive exploration of the Pramana epistemic reasoning engine, demonstrating the 6-phase Navya-Nyaya methodology for systematic logical problem-solving."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup & Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies (with Colab detection)\n",
        "import sys\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "\n",
        "# Check if running in Colab\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "\n",
        "# Core packages (always needed)\n",
        "core_packages = [\n",
        "    \"ipywidgets>=8.0.0\",\n",
        "    \"ipython>=8.0.0\",\n",
        "    \"pydantic>=2.0.0\",\n",
        "    \"pyyaml>=6.0\",\n",
        "    \"requests\",\n",
        "]\n",
        "\n",
        "# Backend-specific packages (install on demand)\n",
        "# - Ollama: pip install ollama\n",
        "# - llama.cpp: pip install llama-cpp-python\n",
        "# - HF Inference: pip install huggingface_hub\n",
        "# - Transformers: pip install transformers torch accelerate peft\n",
        "# - OpenWebUI: pip install openai\n",
        "\n",
        "def install_packages(pkgs, quiet=True):\n",
        "    \"\"\"Install packages with pip.\"\"\"\n",
        "    cmd = [sys.executable, \"-m\", \"pip\", \"install\"]\n",
        "    if quiet:\n",
        "        cmd.append(\"-q\")\n",
        "    cmd.extend(pkgs)\n",
        "    subprocess.check_call(cmd)\n",
        "\n",
        "install_packages(core_packages)\n",
        "\n",
        "if IN_COLAB:\n",
        "    from google.colab import output\n",
        "    output.enable_custom_widget_manager()\n",
        "\n",
        "print(\"✓ Core dependencies installed\")\n",
        "print(f\"✓ Environment: {'Google Colab' if IN_COLAB else 'Local'}\")\n",
        "print()\n",
        "print(\"Backend-specific packages (install as needed):\")\n",
        "print(\"  Ollama:       pip install ollama\")\n",
        "print(\"  llama.cpp:    pip install llama-cpp-python\")\n",
        "print(\"  HF Inference: pip install huggingface_hub\")\n",
        "print(\"  Transformers: pip install transformers torch accelerate peft\")\n",
        "print(\"  OpenWebUI:    pip install openai\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import core modules\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "from getpass import getpass\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "from IPython.display import display, HTML, Markdown\n",
        "import ipywidgets as widgets\n",
        "from ipywidgets import interact, interactive, fixed, HBox, VBox, Output\n",
        "\n",
        "# Import Pramana backend (self-contained, no external dependencies)\n",
        "from pramana_backend import (\n",
        "    create_backend,\n",
        "    STAGE_CONFIGS,\n",
        "    build_user_prompt,\n",
        "    is_colab,\n",
        "    EXAMPLE_PROBLEMS,\n",
        "    load_test_problems,\n",
        "    parse_nyaya_phases,\n",
        "    validate_structure as backend_validate_structure,\n",
        "    score_content_quality as backend_score_content_quality,\n",
        "    extract_final_answer,\n",
        "    score_answers,\n",
        "    setup_ollama,\n",
        "    download_gguf,\n",
        ")\n",
        "\n",
        "print(\"✓ Modules imported (self-contained, no project dependencies)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration: Backend selection and credentials\n",
        "backend_dropdown = widgets.Dropdown(\n",
        "    options=[\n",
        "        (\"Transformers (Local GPU/CPU)\", \"transformers\"),\n",
        "        (\"HuggingFace Inference API\", \"hf_inference\"),\n",
        "        (\"Ollama (Local)\", \"ollama\"),\n",
        "        (\"llama.cpp (GGUF)\", \"llamacpp\"),\n",
        "        (\"OpenWebUI API\", \"openwebui\"),\n",
        "    ],\n",
        "    value=\"transformers\",\n",
        "    description=\"Backend:\",\n",
        "    style={\"description_width\": \"initial\"},\n",
        ")\n",
        "\n",
        "stage_dropdown = widgets.Dropdown(\n",
        "    options=list(STAGE_CONFIGS.keys()),\n",
        "    value=\"Stage 0\",\n",
        "    description=\"Stage:\",\n",
        "    style={\"description_width\": \"initial\"},\n",
        ")\n",
        "\n",
        "model_variant_dropdown = widgets.Dropdown(\n",
        "    options=[(\"Tuned model\", \"tuned\"), (\"Base model\", \"base\"), (\"Both (comparison)\", \"both\")],\n",
        "    value=\"both\",\n",
        "    description=\"Model:\",\n",
        "    style={\"description_width\": \"initial\"},\n",
        ")\n",
        "\n",
        "# Credential entry\n",
        "hf_token_input = widgets.Password(\n",
        "    value=\"\",\n",
        "    placeholder=\"Enter HF_TOKEN (optional for Transformers/HF Inference)\",\n",
        "    description=\"HF Token:\",\n",
        "    style={\"description_width\": \"initial\"},\n",
        "    layout=widgets.Layout(width=\"95%\"),\n",
        ")\n",
        "\n",
        "# Backend-specific settings\n",
        "ollama_model_input = widgets.Text(\n",
        "    value=\"nyaya-llama-3b-stage0\",\n",
        "    placeholder=\"e.g. nyaya-llama-3b-stage0 or llama3.2:3b\",\n",
        "    description=\"Ollama model:\",\n",
        "    style={\"description_width\": \"initial\"},\n",
        "    layout=widgets.Layout(width=\"95%\"),\n",
        ")\n",
        "\n",
        "ollama_url_input = widgets.Text(\n",
        "    value=\"http://localhost:11434\",\n",
        "    description=\"Ollama URL:\",\n",
        "    style={\"description_width\": \"initial\"},\n",
        "    layout=widgets.Layout(width=\"95%\"),\n",
        ")\n",
        "\n",
        "gguf_path_input = widgets.Text(\n",
        "    value=\"\",\n",
        "    placeholder=\"Path to .gguf file (or llama.cpp server URL like http://localhost:8080)\",\n",
        "    description=\"GGUF path/URL:\",\n",
        "    style={\"description_width\": \"initial\"},\n",
        "    layout=widgets.Layout(width=\"95%\"),\n",
        ")\n",
        "\n",
        "openwebui_url_input = widgets.Text(\n",
        "    value=\"http://localhost:3000/api\",\n",
        "    description=\"OpenWebUI URL:\",\n",
        "    style={\"description_width\": \"initial\"},\n",
        "    layout=widgets.Layout(width=\"95%\"),\n",
        ")\n",
        "\n",
        "openwebui_key_input = widgets.Password(\n",
        "    value=\"\",\n",
        "    placeholder=\"OpenWebUI API key\",\n",
        "    description=\"API Key:\",\n",
        "    style={\"description_width\": \"initial\"},\n",
        "    layout=widgets.Layout(width=\"95%\"),\n",
        ")\n",
        "\n",
        "openwebui_model_input = widgets.Text(\n",
        "    value=\"nyaya-llama-3b-stage0\",\n",
        "    placeholder=\"Model name in OpenWebUI\",\n",
        "    description=\"Model name:\",\n",
        "    style={\"description_width\": \"initial\"},\n",
        "    layout=widgets.Layout(width=\"95%\"),\n",
        ")\n",
        "\n",
        "# Collapsible backend-specific settings\n",
        "backend_settings_output = Output()\n",
        "\n",
        "def update_backend_settings(change=None):\n",
        "    \"\"\"Show/hide backend-specific settings based on selection.\"\"\"\n",
        "    with backend_settings_output:\n",
        "        backend_settings_output.clear_output()\n",
        "        bt = backend_dropdown.value\n",
        "        if bt == \"transformers\":\n",
        "            display(widgets.HTML(\"<i>Uses HuggingFace model IDs from stage config. Set HF_TOKEN above for gated models.</i>\"))\n",
        "        elif bt == \"hf_inference\":\n",
        "            display(widgets.HTML(\"<i>Uses HuggingFace Inference API. HF_TOKEN required.</i>\"))\n",
        "        elif bt == \"ollama\":\n",
        "            # Auto-setup button for Ollama\n",
        "            ollama_setup_btn = widgets.Button(description=\"Auto-Setup Ollama\", button_style=\"info\", icon=\"magic\")\n",
        "            ollama_setup_out = Output()\n",
        "            def _ollama_auto(b):\n",
        "                with ollama_setup_out:\n",
        "                    ollama_setup_out.clear_output()\n",
        "                    try:\n",
        "                        install_packages([\"ollama\"])\n",
        "                        model = setup_ollama(model_name=ollama_model_input.value.strip())\n",
        "                        print(f\"✓ Ollama ready with model: {model}\")\n",
        "                    except Exception as e:\n",
        "                        print(f\"✗ Setup failed: {e}\")\n",
        "            ollama_setup_btn.on_click(_ollama_auto)\n",
        "            display(VBox([\n",
        "                widgets.HTML(\"<b>Ollama Settings</b> — Click Auto-Setup to install Ollama + download model, or configure manually\"),\n",
        "                ollama_model_input,\n",
        "                ollama_url_input,\n",
        "                ollama_setup_btn,\n",
        "                ollama_setup_out,\n",
        "            ]))\n",
        "        elif bt == \"llamacpp\":\n",
        "            # Auto-setup button for llama.cpp\n",
        "            gguf_setup_btn = widgets.Button(description=\"Auto-Download GGUF\", button_style=\"info\", icon=\"download\")\n",
        "            gguf_setup_out = Output()\n",
        "            def _gguf_auto(b):\n",
        "                with gguf_setup_out:\n",
        "                    gguf_setup_out.clear_output()\n",
        "                    try:\n",
        "                        install_packages([\"llama-cpp-python\"])\n",
        "                        path = download_gguf()\n",
        "                        gguf_path_input.value = path\n",
        "                        print(f\"✓ GGUF downloaded: {path}\")\n",
        "                    except Exception as e:\n",
        "                        print(f\"✗ Download failed: {e}\")\n",
        "            gguf_setup_btn.on_click(_gguf_auto)\n",
        "            display(VBox([\n",
        "                widgets.HTML(\"<b>llama.cpp Settings</b> — Click Auto-Download or provide path to GGUF / llama.cpp server URL\"),\n",
        "                gguf_path_input,\n",
        "                gguf_setup_btn,\n",
        "                gguf_setup_out,\n",
        "            ]))\n",
        "        elif bt == \"openwebui\":\n",
        "            display(VBox([\n",
        "                widgets.HTML(\"<b>OpenWebUI Settings</b>\"),\n",
        "                openwebui_url_input,\n",
        "                openwebui_key_input,\n",
        "                openwebui_model_input,\n",
        "            ]))\n",
        "\n",
        "backend_dropdown.observe(update_backend_settings, names='value')\n",
        "\n",
        "def setup_config():\n",
        "    \"\"\"Setup configuration from widgets.\"\"\"\n",
        "    global config\n",
        "    backend_type = backend_dropdown.value\n",
        "    stage_name = stage_dropdown.value\n",
        "    variant = model_variant_dropdown.value\n",
        "    hf_token = hf_token_input.value.strip() or os.getenv(\"HF_TOKEN\")\n",
        "    \n",
        "    if hf_token:\n",
        "        os.environ[\"HF_TOKEN\"] = hf_token\n",
        "    \n",
        "    stage_config = STAGE_CONFIGS[stage_name]\n",
        "    \n",
        "    # Build backend based on type\n",
        "    def _make_backend(model_id):\n",
        "        if backend_type == \"transformers\":\n",
        "            return create_backend(\"transformers\", model_id=model_id, hf_token=hf_token)\n",
        "        elif backend_type == \"hf_inference\":\n",
        "            return create_backend(\"hf_inference\", model_id=model_id, hf_token=hf_token)\n",
        "        elif backend_type == \"ollama\":\n",
        "            return create_backend(\"ollama\", model_name=ollama_model_input.value.strip(),\n",
        "                                  base_url=ollama_url_input.value.strip())\n",
        "        elif backend_type == \"llamacpp\":\n",
        "            path_or_url = gguf_path_input.value.strip()\n",
        "            if path_or_url.startswith(\"http\"):\n",
        "                return create_backend(\"llamacpp\", server_url=path_or_url)\n",
        "            else:\n",
        "                return create_backend(\"llamacpp\", model_path=path_or_url)\n",
        "        elif backend_type == \"openwebui\":\n",
        "            return create_backend(\"openwebui\",\n",
        "                                  base_url=openwebui_url_input.value.strip(),\n",
        "                                  api_key=openwebui_key_input.value.strip() or None,\n",
        "                                  model_name=openwebui_model_input.value.strip())\n",
        "    \n",
        "    try:\n",
        "        base_backend = _make_backend(stage_config.base_model_id) if variant in (\"base\", \"both\") else None\n",
        "        tuned_backend = _make_backend(stage_config.tuned_model_id) if variant in (\"tuned\", \"both\") else None\n",
        "        \n",
        "        config = {\n",
        "            \"backend_type\": backend_type,\n",
        "            \"stage_config\": stage_config,\n",
        "            \"base_backend\": base_backend,\n",
        "            \"tuned_backend\": tuned_backend,\n",
        "        }\n",
        "        print(f\"\\u2713 Configuration set: {stage_name} with {backend_type} backend\")\n",
        "        if base_backend:\n",
        "            print(f\"  Base model ready: {stage_config.base_model_id}\")\n",
        "        if tuned_backend:\n",
        "            print(f\"  Tuned model ready: {stage_config.tuned_model_id}\")\n",
        "        return config\n",
        "    except Exception as e:\n",
        "        print(f\"\\u2717 Configuration failed: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "setup_button = widgets.Button(\n",
        "    description=\"Apply Configuration\",\n",
        "    button_style=\"primary\",\n",
        "    icon=\"check\",\n",
        ")\n",
        "\n",
        "config_output = Output()\n",
        "\n",
        "def on_setup_click(button):\n",
        "    with config_output:\n",
        "        config_output.clear_output()\n",
        "        setup_config()\n",
        "\n",
        "setup_button.on_click(on_setup_click)\n",
        "\n",
        "# Initial render of backend settings\n",
        "update_backend_settings()\n",
        "\n",
        "display(VBox([\n",
        "    widgets.HTML(\"<h3>Configuration</h3>\"),\n",
        "    backend_dropdown,\n",
        "    stage_dropdown,\n",
        "    model_variant_dropdown,\n",
        "    hf_token_input,\n",
        "    backend_settings_output,\n",
        "    setup_button,\n",
        "    config_output,\n",
        "]))\n",
        "\n",
        "config = None  # Will be set after user clicks Apply"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Introduction to Navya-Nyaya Reasoning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### What is Navya-Nyaya?\n",
        "\n",
        "Navya-Nyaya (\"New Logic\") is a 2,500-year-old Indian epistemological system that provides a structured methodology for systematic reasoning. Unlike Western formal logic, Navya-Nyaya integrates logic and epistemology, requiring explicit grounding in concrete examples and universal rules."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### The 6-Phase Framework\n",
        "\n",
        "Pramana enforces a structured 6-phase Nyaya methodology:\n",
        "\n",
        "1. **Samshaya (Doubt Analysis)** - Classify the type of uncertainty/ambiguity\n",
        "2. **Pramana (Evidence Sources)** - Identify valid knowledge sources:\n",
        "   - Pratyaksha (Direct Perception)\n",
        "   - Anumana (Inference)\n",
        "   - Upamana (Comparison)\n",
        "   - Shabda (Testimony)\n",
        "3. **Pancha Avayava (5-Member Syllogism)** - Construct formal argument with:\n",
        "   - Pratijna (Thesis)\n",
        "   - Hetu (Reason)\n",
        "   - Udaharana (Universal Example)\n",
        "   - Upanaya (Application)\n",
        "   - Nigamana (Conclusion)\n",
        "4. **Tarka (Counterfactual Testing)** - Use reductio ad absurdum to verify conclusions\n",
        "5. **Hetvabhasa (Fallacy Detection)** - Check for reasoning errors\n",
        "6. **Nirnaya (Ascertainment)** - Reach definitive conclusion or explicitly state insufficient evidence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load example from embedded data (no external files needed)\n",
        "example = EXAMPLE_PROBLEMS[0]  # pramana-001: constraint satisfaction\n",
        "\n",
        "display(Markdown(f\"## Example Problem: {example['id']}\\n\\n{example['problem']}\"))\n",
        "display(Markdown(f\"**Ground Truth:** {example['ground_truth']}\"))\n",
        "display(Markdown(f\"**Problem Type:** {example['problem_type']} | **Difficulty:** {example['difficulty']}\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Phase 1: Samshaya (Doubt Analysis)\n",
        "\n",
        "The example demonstrates **Samana Dharma Upapatti** (Multiple possibilities share similar properties):\n",
        "\n",
        "- There are three people and three pets, creating multiple possible assignments\n",
        "- Without systematic reasoning, we cannot determine which person has which pet\n",
        "- The doubt arises because multiple arrangements are conceivable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Phase 2: Pramana (Sources of Knowledge)\n",
        "\n",
        "The example identifies:\n",
        "\n",
        "- **Pratyaksha**: Directly stated constraints (\"Alice does not have the cat\", \"Bob has the dog\", etc.)\n",
        "- **Anumana**: Inferences like \"If Bob has the dog, then neither Alice nor Carol has the dog\"\n",
        "- **Upamana**: Comparison to constraint satisfaction problems with mutual exclusivity\n",
        "- **Shabda**: Logical principles (Law of Excluded Middle, Non-Contradiction, etc.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Phase 3: Pancha Avayava (5-Member Syllogism)\n",
        "\n",
        "The example constructs three syllogisms:\n",
        "\n",
        "1. **Establishing Bob's Pet**: Pratijna=\"Bob has the dog\", supported by direct constraint\n",
        "2. **Establishing Alice's Pet**: Pratijna=\"Alice has the fish\", via elimination (cannot have cat or dog)\n",
        "3. **Establishing Carol's Pet**: Pratijna=\"Carol has the cat\", via completeness principle\n",
        "\n",
        "Each syllogism includes all 5 members with explicit Udaharana (universal rules) and Upanaya (application)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Phase 4: Tarka (Counterfactual Testing)\n",
        "\n",
        "The example uses reductio ad absurdum:\n",
        "\n",
        "- **Hypothesis**: \"Suppose Carol does not have the cat\"\n",
        "- **Consequence**: This leads to Carol having no pet, violating completeness\n",
        "- **Analysis**: This is absurd given the problem constraints\n",
        "- **Resolution**: Therefore, Carol must have the cat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Phase 5: Hetvabhasa (Fallacy Check)\n",
        "\n",
        "The example checks for:\n",
        "\n",
        "- **Savyabhichara** (Erratic reasoning): None detected\n",
        "- **Viruddha** (Contradictory reasoning): None detected\n",
        "- **Prakaranasama** (Circular reasoning): None detected\n",
        "- **Sadhyasama** (Begging the question): None detected"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Phase 6: Nirnaya (Ascertainment)\n",
        "\n",
        "**Status**: Definitive Knowledge\n",
        "\n",
        "**Final Answer**: Alice has the fish, Bob has the dog, and Carol has the cat.\n",
        "\n",
        "**Confidence**: High - The solution is logically necessary given the constraints."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Interactive Comparison: Base vs Tuned"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load example problems (self-contained, no external files needed)\n",
        "examples = load_test_problems(\"embedded\")\n",
        "print(f\"✓ Loaded {len(examples)} embedded examples\")\n",
        "\n",
        "# Display problem list\n",
        "for i, ex in enumerate(examples):\n",
        "    print(f\"  {i+1}. [{ex['id']}] {ex['problem_type']} ({ex['difficulty']})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example selector and generation controls\n",
        "example_selector = widgets.Dropdown(\n",
        "    options=[(ex[\"id\"], idx) for idx, ex in enumerate(examples)],\n",
        "    description=\"Example:\",\n",
        "    style={\"description_width\": \"initial\"},\n",
        ")\n",
        "\n",
        "# --- Hyperparameter controls (matching HF Space app) ---\n",
        "max_tokens_slider = widgets.IntSlider(\n",
        "    value=2048,\n",
        "    min=64,\n",
        "    max=4096,\n",
        "    step=32,\n",
        "    description=\"Max new tokens:\",\n",
        "    style={\"description_width\": \"initial\"},\n",
        "    layout=widgets.Layout(width=\"95%\"),\n",
        ")\n",
        "\n",
        "temperature_slider = widgets.FloatSlider(\n",
        "    value=0.0,\n",
        "    min=0.0,\n",
        "    max=1.5,\n",
        "    step=0.05,\n",
        "    description=\"Temperature:\",\n",
        "    style={\"description_width\": \"initial\"},\n",
        "    layout=widgets.Layout(width=\"95%\"),\n",
        ")\n",
        "\n",
        "top_p_slider = widgets.FloatSlider(\n",
        "    value=1.0,\n",
        "    min=0.0,\n",
        "    max=1.0,\n",
        "    step=0.05,\n",
        "    description=\"Top-p:\",\n",
        "    style={\"description_width\": \"initial\"},\n",
        "    layout=widgets.Layout(width=\"95%\"),\n",
        ")\n",
        "\n",
        "top_k_slider = widgets.IntSlider(\n",
        "    value=0,\n",
        "    min=0,\n",
        "    max=200,\n",
        "    step=5,\n",
        "    description=\"Top-k:\",\n",
        "    style={\"description_width\": \"initial\"},\n",
        "    layout=widgets.Layout(width=\"95%\"),\n",
        ")\n",
        "\n",
        "generate_button = widgets.Button(\n",
        "    description=\"Generate\",\n",
        "    button_style=\"primary\",\n",
        "    icon=\"play\",\n",
        ")\n",
        "\n",
        "output_area = Output()\n",
        "\n",
        "def generate_comparison(button):\n",
        "    \"\"\"Generate outputs from both models and display side-by-side.\"\"\"\n",
        "    if config is None:\n",
        "        with output_area:\n",
        "            print(\"⚠ Please configure backend and stage first\")\n",
        "        return\n",
        "    \n",
        "    with output_area:\n",
        "        output_area.clear_output()\n",
        "        \n",
        "        idx = example_selector.value\n",
        "        example = examples[idx]\n",
        "        \n",
        "        print(f\"Generating for: {example['id']}\")\n",
        "        print(\"=\" * 80)\n",
        "        \n",
        "        # Build prompt\n",
        "        user_prompt = build_user_prompt(example[\"problem\"])\n",
        "        stage_config = config[\"stage_config\"]\n",
        "        \n",
        "        # Generation parameters\n",
        "        gen_kwargs = dict(\n",
        "            system_prompt=stage_config.system_prompt,\n",
        "            max_new_tokens=max_tokens_slider.value,\n",
        "            temperature=temperature_slider.value,\n",
        "            top_p=top_p_slider.value,\n",
        "            top_k=top_k_slider.value,\n",
        "        )\n",
        "        \n",
        "        # Generate from base model\n",
        "        print(f\"\\n[Base Model] Generating (max_tokens={gen_kwargs['max_new_tokens']}, \"\n",
        "              f\"temp={gen_kwargs['temperature']}, top_p={gen_kwargs['top_p']}, top_k={gen_kwargs['top_k']})...\")\n",
        "        try:\n",
        "            base_output = config[\"base_backend\"].generate(user_prompt, **gen_kwargs)\n",
        "        except Exception as e:\n",
        "            base_output = f\"Error: {e}\"\n",
        "        \n",
        "        # Generate from tuned model\n",
        "        print(\"[Tuned Model] Generating...\")\n",
        "        try:\n",
        "            tuned_output = config[\"tuned_backend\"].generate(user_prompt, **gen_kwargs)\n",
        "        except Exception as e:\n",
        "            tuned_output = f\"Error: {e}\"\n",
        "        \n",
        "        # Display side-by-side\n",
        "        display(HTML(\"\"\"\n",
        "        <style>\n",
        "        .comparison-container { display: flex; gap: 20px; }\n",
        "        .model-output { flex: 1; border: 1px solid #ccc; padding: 10px; border-radius: 5px; }\n",
        "        .base-model { background-color: #fff3cd; }\n",
        "        .tuned-model { background-color: #d1ecf1; }\n",
        "        </style>\n",
        "        \"\"\"))\n",
        "        \n",
        "        display(HTML(f\"\"\"\n",
        "        <div class=\"comparison-container\">\n",
        "            <div class=\"model-output base-model\">\n",
        "                <h3>Base Model ({stage_config.base_model_id})</h3>\n",
        "                <pre style=\"white-space: pre-wrap;\">{base_output}</pre>\n",
        "            </div>\n",
        "            <div class=\"model-output tuned-model\">\n",
        "                <h3>Tuned Model ({stage_config.tuned_model_id})</h3>\n",
        "                <pre style=\"white-space: pre-wrap;\">{tuned_output}</pre>\n",
        "            </div>\n",
        "        </div>\n",
        "        \"\"\"))\n",
        "        \n",
        "        # Store outputs for analysis\n",
        "        global last_base_output, last_tuned_output\n",
        "        last_base_output = base_output\n",
        "        last_tuned_output = tuned_output\n",
        "\n",
        "generate_button.on_click(generate_comparison)\n",
        "\n",
        "display(VBox([\n",
        "    widgets.HTML(\"<h3>Generation Controls</h3>\"),\n",
        "    example_selector,\n",
        "    widgets.HTML(\"<b>Hyperparameters</b> (adjust for your hardware — larger tokens = longer output):\"),\n",
        "    max_tokens_slider,\n",
        "    temperature_slider,\n",
        "    top_p_slider,\n",
        "    top_k_slider,\n",
        "    generate_button,\n",
        "    output_area,\n",
        "]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Phase highlighting function\n",
        "def highlight_phases(text: str) -> str:\n",
        "    \"\"\"Add HTML highlighting to Nyaya phases.\"\"\"\n",
        "    phases = [\n",
        "        (r\"## Samshaya.*?\\n\", \"#ffeb3b\"),\n",
        "        (r\"## Pramana.*?\\n\", \"#4caf50\"),\n",
        "        (r\"## Pancha Avayava.*?\\n\", \"#2196f3\"),\n",
        "        (r\"## Tarka.*?\\n\", \"#ff9800\"),\n",
        "        (r\"## Hetvabhasa.*?\\n\", \"#9c27b0\"),\n",
        "        (r\"## Nirnaya.*?\\n\", \"#f44336\"),\n",
        "    ]\n",
        "    \n",
        "    for pattern, color in phases:\n",
        "        text = re.sub(\n",
        "            pattern,\n",
        "            f'<span style=\"background-color: {color}; padding: 2px 4px; border-radius: 3px; font-weight: bold;\">\\\\g<0></span>',\n",
        "            text,\n",
        "            flags=re.IGNORECASE,\n",
        "        )\n",
        "    \n",
        "    return text\n",
        "\n",
        "# Display highlighted output\n",
        "if 'last_base_output' in globals():\n",
        "    display(HTML(f\"<h3>Base Model Output (Highlighted)</h3><pre>{highlight_phases(last_base_output)}</pre>\"))\n",
        "if 'last_tuned_output' in globals():\n",
        "    display(HTML(f\"<h3>Tuned Model Output (Highlighted)</h3><pre>{highlight_phases(last_tuned_output)}</pre>\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Phase-by-Phase Output Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Phase parsing with regex\n",
        "def parse_phases(text: str) -> Dict[str, Optional[str]]:\n",
        "    \"\"\"Parse 6 phases from model output using regex.\"\"\"\n",
        "    phases = {}\n",
        "    \n",
        "    # Phase patterns\n",
        "    patterns = {\n",
        "        \"samshaya\": r\"##\\s+Samshaya.*?\\n(.*?)(?=##\\s+|\\Z)\",\n",
        "        \"pramana\": r\"##\\s+Pramana.*?\\n(.*?)(?=##\\s+|\\Z)\",\n",
        "        \"pancha_avayava\": r\"##\\s+Pancha Avayava.*?\\n(.*?)(?=##\\s+|\\Z)\",\n",
        "        \"tarka\": r\"##\\s+Tarka.*?\\n(.*?)(?=##\\s+|\\Z)\",\n",
        "        \"hetvabhasa\": r\"##\\s+Hetvabhasa.*?\\n(.*?)(?=##\\s+|\\Z)\",\n",
        "        \"nirnaya\": r\"##\\s+Nirnaya.*?\\n(.*?)(?=##\\s+|\\Z)\",\n",
        "    }\n",
        "    \n",
        "    for phase_name, pattern in patterns.items():\n",
        "        match = re.search(pattern, text, re.DOTALL | re.IGNORECASE)\n",
        "        phases[phase_name] = match.group(1).strip() if match else None\n",
        "    \n",
        "    return phases\n",
        "\n",
        "# Test parsing\n",
        "if 'last_tuned_output' in globals():\n",
        "    parsed = parse_phases(last_tuned_output)\n",
        "    print(\"Parsed Phases:\")\n",
        "    for phase, content in parsed.items():\n",
        "        status = \"✓\" if content else \"✗\"\n",
        "        length = len(content) if content else 0\n",
        "        print(f\"{status} {phase}: {length} chars\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Scorecard table\n",
        "def create_scorecard(base_output: str, tuned_output: str) -> HTML:\n",
        "    \"\"\"Create a scorecard comparing phase completeness.\"\"\"\n",
        "    base_phases = parse_phases(base_output)\n",
        "    tuned_phases = parse_phases(tuned_output)\n",
        "    \n",
        "    phase_names = [\n",
        "        \"Samshaya\",\n",
        "        \"Pramana\",\n",
        "        \"Pancha Avayava\",\n",
        "        \"Tarka\",\n",
        "        \"Hetvabhasa\",\n",
        "        \"Nirnaya\",\n",
        "    ]\n",
        "    \n",
        "    rows = []\n",
        "    for phase in phase_names:\n",
        "        phase_key = phase.lower().replace(\" \", \"_\")\n",
        "        base_present = \"✓\" if base_phases.get(phase_key) else \"✗\"\n",
        "        tuned_present = \"✓\" if tuned_phases.get(phase_key) else \"✗\"\n",
        "        \n",
        "        base_color = \"green\" if base_present == \"✓\" else \"red\"\n",
        "        tuned_color = \"green\" if tuned_present == \"✓\" else \"red\"\n",
        "        \n",
        "        rows.append(f\"\"\"\n",
        "        <tr>\n",
        "            <td><strong>{phase}</strong></td>\n",
        "            <td style=\"color: {base_color};\">{base_present}</td>\n",
        "            <td style=\"color: {tuned_color};\">{tuned_present}</td>\n",
        "        </tr>\n",
        "        \"\"\")\n",
        "    \n",
        "    html = f\"\"\"\n",
        "    <table border=\"1\" style=\"border-collapse: collapse; width: 100%;\">\n",
        "        <thead>\n",
        "            <tr style=\"background-color: #f0f0f0;\">\n",
        "                <th>Phase</th>\n",
        "                <th>Base Model</th>\n",
        "                <th>Tuned Model</th>\n",
        "            </tr>\n",
        "        </thead>\n",
        "        <tbody>\n",
        "            {''.join(rows)}\n",
        "        </tbody>\n",
        "    </table>\n",
        "    \"\"\"\n",
        "    \n",
        "    return HTML(html)\n",
        "\n",
        "# Display scorecard\n",
        "if 'last_base_output' in globals() and 'last_tuned_output' in globals():\n",
        "    display(create_scorecard(last_base_output, last_tuned_output))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Color-coded visualization\n",
        "def visualize_phases(output: str, title: str = \"Output\") -> HTML:\n",
        "    \"\"\"Create color-coded phase visualization.\"\"\"\n",
        "    phases = parse_phases(output)\n",
        "    \n",
        "    colors = {\n",
        "        \"samshaya\": \"#ffeb3b\",\n",
        "        \"pramana\": \"#4caf50\",\n",
        "        \"pancha_avayava\": \"#2196f3\",\n",
        "        \"tarka\": \"#ff9800\",\n",
        "        \"hetvabhasa\": \"#9c27b0\",\n",
        "        \"nirnaya\": \"#f44336\",\n",
        "    }\n",
        "    \n",
        "    bars = []\n",
        "    for phase_key, color in colors.items():\n",
        "        present = phases.get(phase_key) is not None\n",
        "        width = 100 if present else 0\n",
        "        bg_color = color if present else \"#cccccc\"\n",
        "        \n",
        "        phase_name = phase_key.replace(\"_\", \" \").title()\n",
        "        bars.append(f\"\"\"\n",
        "        <div style=\"margin: 5px 0;\">\n",
        "            <div style=\"display: inline-block; width: 150px;\">{phase_name}</div>\n",
        "            <div style=\"display: inline-block; width: {width}%; height: 20px; background-color: {bg_color}; border-radius: 3px;\"></div>\n",
        "            <span style=\"margin-left: 10px;\">{'✓' if present else '✗'}</span>\n",
        "        </div>\n",
        "        \"\"\")\n",
        "    \n",
        "    html = f\"\"\"\n",
        "    <div style=\"border: 1px solid #ccc; padding: 15px; border-radius: 5px; margin: 10px 0;\">\n",
        "        <h4>{title}</h4>\n",
        "        {''.join(bars)}\n",
        "    </div>\n",
        "    \"\"\"\n",
        "    \n",
        "    return HTML(html)\n",
        "\n",
        "# Display visualizations\n",
        "if 'last_base_output' in globals():\n",
        "    display(visualize_phases(last_base_output, \"Base Model\"))\n",
        "if 'last_tuned_output' in globals():\n",
        "    display(visualize_phases(last_tuned_output, \"Tuned Model\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Structural Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tier 1 validation (adapted from structure.py)\n",
        "def validate_structure(text: str) -> Tuple[bool, List[str]]:\n",
        "    \"\"\"Validate structure using Tier 1 checks.\"\"\"\n",
        "    errors = []\n",
        "    \n",
        "    # Check all 6 phases exist\n",
        "    required_phases = [\n",
        "        \"Samshaya\",\n",
        "        \"Pramana\",\n",
        "        \"Pancha Avayava\",\n",
        "        \"Tarka\",\n",
        "        \"Hetvabhasa\",\n",
        "        \"Nirnaya\",\n",
        "    ]\n",
        "    \n",
        "    for phase in required_phases:\n",
        "        pattern = rf\"##\\s+{re.escape(phase)}.*?\\n\"\n",
        "        if not re.search(pattern, text, re.IGNORECASE):\n",
        "            errors.append(f\"Missing phase: {phase}\")\n",
        "    \n",
        "    # Check Pramana has at least one knowledge source\n",
        "    pramana_match = re.search(r\"##\\s+Pramana.*?\\n(.*?)(?=##\\s+|\\Z)\", text, re.DOTALL | re.IGNORECASE)\n",
        "    if pramana_match:\n",
        "        pramana_text = pramana_match.group(1)\n",
        "        sources = [\"Pratyaksha\", \"Anumana\", \"Upamana\", \"Shabda\"]\n",
        "        found_sources = [s for s in sources if re.search(rf\"###\\s+{re.escape(s)}\", pramana_text, re.IGNORECASE)]\n",
        "        if not found_sources:\n",
        "            errors.append(\"Pramana must have at least one knowledge source\")\n",
        "    \n",
        "    # Check Pancha Avayava has at least one syllogism\n",
        "    pancha_match = re.search(r\"##\\s+Pancha Avayava.*?\\n(.*?)(?=##\\s+|\\Z)\", text, re.DOTALL | re.IGNORECASE)\n",
        "    if pancha_match:\n",
        "        pancha_text = pancha_match.group(1)\n",
        "        syllogism_count = len(re.findall(r\"###\\s+Syllogism\", pancha_text, re.IGNORECASE))\n",
        "        if syllogism_count == 0:\n",
        "            errors.append(\"Pancha Avayava must contain at least one syllogism\")\n",
        "        else:\n",
        "            # Check each syllogism has all 5 members\n",
        "            syllogisms = re.finditer(r\"###\\s+Syllogism.*?\\n(.*?)(?=###\\s+Syllogism|##\\s+|\\Z)\", pancha_text, re.DOTALL | re.IGNORECASE)\n",
        "            for idx, syll_match in enumerate(syllogisms, 1):\n",
        "                syll_text = syll_match.group(1)\n",
        "                required_members = [\"Pratijna\", \"Hetu\", \"Udaharana\", \"Upanaya\", \"Nigamana\"]\n",
        "                missing = []\n",
        "                for member in required_members:\n",
        "                    if not re.search(rf\"\\*\\*{re.escape(member)}.*?\\*\\*:\", syll_text, re.IGNORECASE):\n",
        "                        missing.append(member)\n",
        "                if missing:\n",
        "                    errors.append(f\"Syllogism {idx} missing members: {', '.join(missing)}\")\n",
        "    \n",
        "    return len(errors) == 0, errors\n",
        "\n",
        "# Validate outputs\n",
        "if 'last_base_output' in globals():\n",
        "    is_valid, errors = validate_structure(last_base_output)\n",
        "    print(f\"Base Model Validation: {'✓ PASS' if is_valid else '✗ FAIL'}\")\n",
        "    if errors:\n",
        "        print(\"Errors:\")\n",
        "        for err in errors:\n",
        "            print(f\"  - {err}\")\n",
        "\n",
        "if 'last_tuned_output' in globals():\n",
        "    is_valid, errors = validate_structure(last_tuned_output)\n",
        "    print(f\"\\nTuned Model Validation: {'✓ PASS' if is_valid else '✗ FAIL'}\")\n",
        "    if errors:\n",
        "        print(\"Errors:\")\n",
        "        for err in errors:\n",
        "            print(f\"  - {err}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display validation results with formatting\n",
        "def display_validation_results(output: str, model_name: str):\n",
        "    \"\"\"Display validation results in a formatted way.\"\"\"\n",
        "    is_valid, errors = validate_structure(output)\n",
        "    \n",
        "    status_color = \"green\" if is_valid else \"red\"\n",
        "    status_icon = \"✓\" if is_valid else \"✗\"\n",
        "    \n",
        "    html = f\"\"\"\n",
        "    <div style=\"border: 2px solid {status_color}; padding: 15px; border-radius: 5px; margin: 10px 0;\">\n",
        "        <h3 style=\"color: {status_color};\">{status_icon} {model_name} Validation</h3>\n",
        "        <p><strong>Status:</strong> {'PASS' if is_valid else 'FAIL'}</p>\n",
        "    \"\"\"\n",
        "    \n",
        "    if errors:\n",
        "        html += \"<ul>\"\n",
        "        for err in errors:\n",
        "            html += f\"<li style='color: red;'>{err}</li>\"\n",
        "        html += \"</ul>\"\n",
        "    else:\n",
        "        html += \"<p style='color: green;'>All structural checks passed!</p>\"\n",
        "    \n",
        "    html += \"</div>\"\n",
        "    \n",
        "    return HTML(html)\n",
        "\n",
        "# Display validation\n",
        "if 'last_base_output' in globals():\n",
        "    display(display_validation_results(last_base_output, \"Base Model\"))\n",
        "if 'last_tuned_output' in globals():\n",
        "    display(display_validation_results(last_tuned_output, \"Tuned Model\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Content Quality Scoring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Content quality scoring (adapted from content_quality.py)\n",
        "def score_content_quality(text: str, problem: str) -> Dict[str, float]:\n",
        "    \"\"\"Score content quality using heuristics.\"\"\"\n",
        "    scores = {}\n",
        "    \n",
        "    # Parse phases\n",
        "    phases = parse_phases(text)\n",
        "    \n",
        "    # 1. Pratyaksha grounding\n",
        "    pratyaksha_score = 0.0\n",
        "    if phases.get(\"pramana\"):\n",
        "        pratyaksha_match = re.search(r\"###\\s+Pratyaksha.*?\\n(.*?)(?=###\\s+|##\\s+|\\Z)\", phases[\"pramana\"], re.DOTALL | re.IGNORECASE)\n",
        "        if pratyaksha_match:\n",
        "            pratyaksha_text = pratyaksha_match.group(1)\n",
        "            # Count list items\n",
        "            claims = [line.strip() for line in pratyaksha_text.split(\"\\n\") if line.strip().startswith(\"-\")]\n",
        "            if claims:\n",
        "                # Simple grounding check: see if claim tokens appear in problem\n",
        "                problem_lower = problem.lower()\n",
        "                grounded = sum(1 for claim in claims if any(word in problem_lower for word in claim.lower().split()[:5]))\n",
        "                pratyaksha_score = grounded / len(claims) if claims else 0.0\n",
        "    scores[\"pratyaksha_grounding\"] = pratyaksha_score\n",
        "    \n",
        "    # 2. Udaharana patterns\n",
        "    udaharana_valid = False\n",
        "    if phases.get(\"pancha_avayava\"):\n",
        "        udaharana_patterns = [\n",
        "            r\"\\bwherever\\b.+,\\s*.+\",\n",
        "            r\"\\bwhenever\\b.+\",\n",
        "            r\"\\bin all cases where\\b.+\",\n",
        "            r\"\\bfor any\\b.+\\bif\\b.+\\bthen\\b.+\",\n",
        "        ]\n",
        "        for pattern in udaharana_patterns:\n",
        "            if re.search(pattern, phases[\"pancha_avayava\"], re.IGNORECASE):\n",
        "                udaharana_valid = True\n",
        "                break\n",
        "    scores[\"udaharana_valid\"] = 1.0 if udaharana_valid else 0.0\n",
        "    \n",
        "    # 3. Tarka meaningfulness\n",
        "    tarka_meaningful = False\n",
        "    if phases.get(\"tarka\"):\n",
        "        negation_markers = [\"not\", \"no\", \"never\", \"suppose\", \"assume\", \"contrary\", \"opposite\"]\n",
        "        contradiction_markers = [\"contradiction\", \"contradicts\", \"impossible\", \"cannot\", \"absurd\", \"violates\"]\n",
        "        \n",
        "        tarka_lower = phases[\"tarka\"].lower()\n",
        "        hypothesis_match = re.search(r\"\\*\\*Hypothesis\\*\\*:\\s*(.+?)(?=\\*\\*|\\Z)\", phases[\"tarka\"], re.DOTALL | re.IGNORECASE)\n",
        "        \n",
        "        has_negation = False\n",
        "        if hypothesis_match:\n",
        "            hypothesis = hypothesis_match.group(1).lower()\n",
        "            has_negation = any(marker in hypothesis for marker in negation_markers)\n",
        "        \n",
        "        has_contradiction = any(marker in tarka_lower for marker in contradiction_markers)\n",
        "        tarka_meaningful = has_negation and has_contradiction\n",
        "    scores[\"tarka_meaningful\"] = 1.0 if tarka_meaningful else 0.0\n",
        "    \n",
        "    # 4. Hetvabhasa completeness\n",
        "    hetvabhasa_completeness = 0.0\n",
        "    if phases.get(\"hetvabhasa\"):\n",
        "        fallacy_types = [\"savyabhichara\", \"viruddha\", \"prakaranasama\", \"sadhyasama\", \"asiddha\", \"satpratipaksha\", \"badhita\"]\n",
        "        hetvabhasa_lower = phases[\"hetvabhasa\"].lower()\n",
        "        found_fallacies = sum(1 for ft in fallacy_types if ft in hetvabhasa_lower)\n",
        "        hetvabhasa_completeness = found_fallacies / len(fallacy_types)\n",
        "    scores[\"hetvabhasa_completeness\"] = hetvabhasa_completeness\n",
        "    \n",
        "    # Overall score\n",
        "    scores[\"overall\"] = sum(scores.values()) / len(scores)\n",
        "    \n",
        "    return scores\n",
        "\n",
        "# Score outputs\n",
        "if 'last_base_output' in globals() and examples:\n",
        "    example = examples[example_selector.value if 'example_selector' in globals() else 0]\n",
        "    base_scores = score_content_quality(last_base_output, example[\"problem\"])\n",
        "    print(\"Base Model Content Quality Scores:\")\n",
        "    for metric, score in base_scores.items():\n",
        "        print(f\"  {metric}: {score:.2f}\")\n",
        "\n",
        "if 'last_tuned_output' in globals() and examples:\n",
        "    example = examples[example_selector.value if 'example_selector' in globals() else 0]\n",
        "    tuned_scores = score_content_quality(last_tuned_output, example[\"problem\"])\n",
        "    print(\"\\nTuned Model Content Quality Scores:\")\n",
        "    for metric, score in tuned_scores.items():\n",
        "        print(f\"  {metric}: {score:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize content quality scores\n",
        "def visualize_quality_scores(scores: Dict[str, float], model_name: str) -> HTML:\n",
        "    \"\"\"Create bar chart visualization of quality scores.\"\"\"\n",
        "    metrics = [k for k in scores.keys() if k != \"overall\"]\n",
        "    \n",
        "    bars = []\n",
        "    for metric in metrics:\n",
        "        score = scores[metric]\n",
        "        width = score * 100\n",
        "        color = \"#4caf50\" if score >= 0.7 else \"#ff9800\" if score >= 0.4 else \"#f44336\"\n",
        "        \n",
        "        bars.append(f\"\"\"\n",
        "        <div style=\"margin: 8px 0;\">\n",
        "            <div style=\"display: inline-block; width: 200px;\">{metric.replace('_', ' ').title()}</div>\n",
        "            <div style=\"display: inline-block; width: 300px; background-color: #e0e0e0; border-radius: 3px; position: relative;\">\n",
        "                <div style=\"width: {width}%; height: 20px; background-color: {color}; border-radius: 3px;\"></div>\n",
        "            </div>\n",
        "            <span style=\"margin-left: 10px; font-weight: bold;\">{score:.2f}</span>\n",
        "        </div>\n",
        "        \"\"\")\n",
        "    \n",
        "    overall_score = scores.get(\"overall\", 0.0)\n",
        "    overall_color = \"#4caf50\" if overall_score >= 0.7 else \"#ff9800\" if overall_score >= 0.4 else \"#f44336\"\n",
        "    \n",
        "    html = f\"\"\"\n",
        "    <div style=\"border: 1px solid #ccc; padding: 15px; border-radius: 5px; margin: 10px 0;\">\n",
        "        <h4>{model_name} Content Quality</h4>\n",
        "        {''.join(bars)}\n",
        "        <hr>\n",
        "        <div style=\"margin-top: 10px;\">\n",
        "            <strong>Overall Score: <span style=\"color: {overall_color}; font-size: 1.2em;\">{overall_score:.2f}</span></strong>\n",
        "        </div>\n",
        "    </div>\n",
        "    \"\"\"\n",
        "    \n",
        "    return HTML(html)\n",
        "\n",
        "# Display quality scores\n",
        "if 'last_base_output' in globals() and examples:\n",
        "    example = examples[example_selector.value if 'example_selector' in globals() else 0]\n",
        "    base_scores = score_content_quality(last_base_output, example[\"problem\"])\n",
        "    display(visualize_quality_scores(base_scores, \"Base Model\"))\n",
        "\n",
        "if 'last_tuned_output' in globals() and examples:\n",
        "    example = examples[example_selector.value if 'example_selector' in globals() else 0]\n",
        "    tuned_scores = score_content_quality(last_tuned_output, example[\"problem\"])\n",
        "    display(visualize_quality_scores(tuned_scores, \"Tuned Model\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Interactive Learning Exercises"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exercise 1: Identify the doubt type\n",
        "exercise1_problem = \"\"\"\n",
        "Problem: If it rains, the ground gets wet. The ground is wet. Did it rain?\n",
        "\"\"\"\n",
        "\n",
        "exercise1_question = widgets.HTML(\n",
        "    value=\"\"\"\n",
        "    <h4>Exercise 1: Doubt Type Identification</h4>\n",
        "    <p>What type of doubt (Samshaya) is present in this problem?</p>\n",
        "    <pre>{exercise1_problem}</pre>\n",
        "    \"\"\".format(exercise1_problem=exercise1_problem)\n",
        ")\n",
        "\n",
        "exercise1_answer = widgets.Dropdown(\n",
        "    options=[\n",
        "        (\"Select...\", \"\"),\n",
        "        (\"Samana Dharma Upapatti\", \"samana_dharma_upapatti\"),\n",
        "        (\"Vipratipatti\", \"vipratipatti\"),\n",
        "        (\"Anadhyavasaya\", \"anadhyavasaya\"),\n",
        "    ],\n",
        "    description=\"Answer:\",\n",
        ")\n",
        "\n",
        "exercise1_feedback = Output()\n",
        "\n",
        "def check_exercise1(change):\n",
        "    with exercise1_feedback:\n",
        "        exercise1_feedback.clear_output()\n",
        "        if exercise1_answer.value == \"vipratipatti\":\n",
        "            display(HTML(\"<p style='color: green;'>✓ Correct! This is Vipratipatti (conflicting possibilities) - rain could cause wet ground, but so could other things.</p>\"))\n",
        "        elif exercise1_answer.value:\n",
        "            display(HTML(\"<p style='color: red;'>✗ Not quite. Think about whether there are conflicting possible explanations for the wet ground.</p>\"))\n",
        "\n",
        "exercise1_answer.observe(check_exercise1, names='value')\n",
        "\n",
        "display(VBox([exercise1_question, exercise1_answer, exercise1_feedback]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exercise 2: Identify Pramana sources\n",
        "exercise2_text = \"\"\"\n",
        "In a logic puzzle: \"Alice says she has the red ball. Bob says Alice is lying.\"\n",
        "\n",
        "What type of Pramana is \"Alice says she has the red ball\"?\n",
        "\"\"\"\n",
        "\n",
        "exercise2_question = widgets.HTML(\n",
        "    value=f\"\"\"\n",
        "    <h4>Exercise 2: Pramana Source Identification</h4>\n",
        "    <p>{exercise2_text}</p>\n",
        "    \"\"\".format(exercise2_text=exercise2_text)\n",
        ")\n",
        "\n",
        "exercise2_answer = widgets.Dropdown(\n",
        "    options=[\n",
        "        (\"Select...\", \"\"),\n",
        "        (\"Pratyaksha (Direct Perception)\", \"pratyaksha\"),\n",
        "        (\"Anumana (Inference)\", \"anumana\"),\n",
        "        (\"Upamana (Comparison)\", \"upamana\"),\n",
        "        (\"Shabda (Testimony)\", \"shabda\"),\n",
        "    ],\n",
        "    description=\"Answer:\",\n",
        ")\n",
        "\n",
        "exercise2_feedback = Output()\n",
        "\n",
        "def check_exercise2(change):\n",
        "    with exercise2_feedback:\n",
        "        exercise2_feedback.clear_output()\n",
        "        if exercise2_answer.value == \"shabda\":\n",
        "            display(HTML(\"<p style='color: green;'>✓ Correct! This is Shabda (testimony) - we are told what Alice said, not what we directly observed.</p>\"))\n",
        "        elif exercise2_answer.value:\n",
        "            display(HTML(\"<p style='color: red;'>✗ Not quite. Think about whether this is something we directly observed or something we were told.</p>\"))\n",
        "\n",
        "exercise2_answer.observe(check_exercise2, names='value')\n",
        "\n",
        "display(VBox([exercise2_question, exercise2_answer, exercise2_feedback]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exercise 3: Complete the syllogism\n",
        "exercise3_text = \"\"\"\n",
        "Complete this Pancha Avayava syllogism:\n",
        "\n",
        "Pratijna (Thesis): All birds can fly.\n",
        "Hetu (Reason): Because they have wings.\n",
        "Udaharana (Universal Example): ?\n",
        "Upanaya (Application): ?\n",
        "Nigamana (Conclusion): ?\n",
        "\"\"\"\n",
        "\n",
        "exercise3_question = widgets.HTML(\n",
        "    value=f\"\"\"\n",
        "    <h4>Exercise 3: Complete the Syllogism</h4>\n",
        "    <pre>{exercise3_text}</pre>\n",
        "    \"\"\".format(exercise3_text=exercise3_text)\n",
        ")\n",
        "\n",
        "exercise3_udaharana = widgets.Textarea(\n",
        "    value=\"\",\n",
        "    placeholder=\"Enter Udaharana (Universal Example)...\",\n",
        "    description=\"Udaharana:\",\n",
        "    layout=widgets.Layout(width=\"100%\", height=\"80px\"),\n",
        ")\n",
        "\n",
        "exercise3_feedback = Output()\n",
        "\n",
        "def check_exercise3(change):\n",
        "    with exercise3_feedback:\n",
        "        exercise3_feedback.clear_output()\n",
        "        answer = exercise3_udaharana.value.lower()\n",
        "        \n",
        "        # Check for universal rule pattern\n",
        "        has_universal = any(word in answer for word in [\"wherever\", \"whenever\", \"all\", \"any\", \"every\"])\n",
        "        has_example = any(word in answer for word in [\"eagle\", \"sparrow\", \"bird\", \"example\", \"instance\"])\n",
        "        \n",
        "        if has_universal and has_example:\n",
        "            display(HTML(\"<p style='color: green;'>✓ Good! Your Udaharana includes both a universal rule and a concrete example. Example: 'Wherever there is a bird with wings, it can fly. For example, an eagle has wings and can fly.'</p>\"))\n",
        "        elif has_universal:\n",
        "            display(HTML(\"<p style='color: orange;'>⚠ You have a universal rule, but try to include a concrete example too (e.g., 'like an eagle').</p>\"))\n",
        "        else:\n",
        "            display(HTML(\"<p style='color: red;'>✗ Try to include both a universal rule (using words like 'wherever', 'whenever', 'all') and a concrete example.</p>\"))\n",
        "\n",
        "exercise3_udaharana.observe(check_exercise3, names='value')\n",
        "\n",
        "display(VBox([exercise3_question, exercise3_udaharana, exercise3_feedback]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Try Your Own Problem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Free-form problem input\n",
        "problem_input = widgets.Textarea(\n",
        "    value=\"\",\n",
        "    placeholder=\"Enter your logical problem here...\",\n",
        "    description=\"Problem:\",\n",
        "    layout=widgets.Layout(width=\"100%\", height=\"150px\"),\n",
        ")\n",
        "\n",
        "custom_generate_button = widgets.Button(\n",
        "    description=\"Generate Nyaya Reasoning\",\n",
        "    button_style=\"success\",\n",
        "    icon=\"rocket\",\n",
        ")\n",
        "\n",
        "custom_output_area = Output()\n",
        "\n",
        "def generate_custom(button):\n",
        "    \"\"\"Generate reasoning for custom problem.\"\"\"\n",
        "    if config is None:\n",
        "        with custom_output_area:\n",
        "            print(\"⚠ Please configure backend and stage first\")\n",
        "        return\n",
        "    \n",
        "    problem = problem_input.value.strip()\n",
        "    if not problem:\n",
        "        with custom_output_area:\n",
        "            print(\"⚠ Please enter a problem\")\n",
        "        return\n",
        "    \n",
        "    with custom_output_area:\n",
        "        custom_output_area.clear_output()\n",
        "        \n",
        "        print(f\"Generating reasoning for your problem...\")\n",
        "        print(\"=\" * 80)\n",
        "        \n",
        "        # Build prompt\n",
        "        user_prompt = build_user_prompt(problem)\n",
        "        stage_config = config[\"stage_config\"]\n",
        "        \n",
        "        # Generate from tuned model\n",
        "        try:\n",
        "            output = config[\"tuned_backend\"].generate(\n",
        "                user_prompt,\n",
        "                system_prompt=stage_config.system_prompt,\n",
        "                max_new_tokens=max_tokens_slider.value if 'max_tokens_slider' in globals() else 2048,\n",
        "                temperature=temperature_slider.value if 'temperature_slider' in globals() else 0.0,\n",
        "                top_p=top_p_slider.value if 'top_p_slider' in globals() else 1.0,\n",
        "                top_k=top_k_slider.value if 'top_k_slider' in globals() else 0,\n",
        "            )\n",
        "            \n",
        "            # Display output with highlighting\n",
        "            display(Markdown(f\"## Generated Reasoning\\n\\n{output}\"))\n",
        "            \n",
        "            # Validate structure\n",
        "            is_valid, errors = validate_structure(output)\n",
        "            if is_valid:\n",
        "                display(HTML(\"<p style='color: green;'>✓ Structural validation passed!</p>\"))\n",
        "            else:\n",
        "                display(HTML(f\"<p style='color: orange;'>⚠ Structural issues found:</p><ul>{''.join(f'<li>{e}</li>' for e in errors)}</ul>\"))\n",
        "            \n",
        "            # Score content quality\n",
        "            scores = score_content_quality(output, problem)\n",
        "            display(visualize_quality_scores(scores, \"Your Problem\"))\n",
        "            \n",
        "        except Exception as e:\n",
        "            display(HTML(f\"<p style='color: red;'>Error: {e}</p>\"))\n",
        "\n",
        "custom_generate_button.on_click(generate_custom)\n",
        "\n",
        "display(VBox([\n",
        "    widgets.HTML(\"<h3>Try Your Own Problem</h3>\"),\n",
        "    problem_input,\n",
        "    custom_generate_button,\n",
        "    custom_output_area,\n",
        "]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Summary\n",
        "\n",
        "This notebook demonstrates:\n",
        "\n",
        "1. **Structured Reasoning**: The 6-phase Navya-Nyaya methodology\n",
        "2. **Model Comparison**: Side-by-side comparison of base vs tuned models\n",
        "3. **Validation**: Structural and content quality validation\n",
        "4. **Interactive Learning**: Exercises to understand Nyaya concepts\n",
        "5. **Custom Problems**: Generate reasoning for your own logical problems\n",
        "\n",
        "For more information, see the [Pramana documentation](docs/) and [CLAUDE.md](CLAUDE.md)."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
